# Parquet Examples â€“ Multi-language

Este repositorio contiene ejemplos simples y claros de **lectura y escritura de archivos Parquet**
usando diferentes lenguajes de programaciÃ³n.

El objetivo principal es **entender Parquet como formato columnar** y mostrar que,
independientemente del lenguaje con el que se escriba, **Spark puede leerlos sin problema**.

---

## ğŸ§  Â¿QuÃ© es Parquet?

Parquet es un **formato de almacenamiento columnar**, optimizado para:

- AnalÃ­tica
- Big Data
- Lecturas selectivas por columnas
- CompresiÃ³n eficiente
- IntegraciÃ³n con motores como **Apache Spark**

Spark **no depende del lenguaje que generÃ³ el archivo**, solo del formato.

---

## ğŸ“‚ Estructura del proyecto

learn-data-manipulation-basic/
â”‚
â”œâ”€â”€ python/
â”‚ â””â”€â”€ parquet_example.py
â”‚
â”œâ”€â”€ java/
â”‚ â””â”€â”€ ParquetExample.java
â”‚
â”œâ”€â”€ r/
â”‚ â””â”€â”€ parquet_example.R
â”‚
â””â”€â”€ README.md


---

## ğŸ Python â€“ pandas + pyarrow

**Archivo:** `parquet_example.py`

- Escritura usando `to_parquet`
- Lectura usando `read_parquet`
- Engine: `pyarrow`
- CompresiÃ³n: `snappy`

Uso tÃ­pico:
- Data analysis
- ETL livianos
- Prototipado rÃ¡pido

---

## â˜• Java â€“ Apache Spark

**Archivo:** `parquet_example.java`

- Uso nativo de Spark
- Escritura y lectura en formato Parquet
- Produce una carpeta Parquet (mÃºltiples archivos)

Uso tÃ­pico:
- Pipelines de Big Data
- Lakehouse
- Procesamiento distribuido

---

## ğŸ“Š R â€“ arrow

**Archivo:** `parquet_example.R`

- Escritura con `write_parquet`
- Lectura con `read_parquet`
- Basado en Apache Arrow

Uso tÃ­pico:
- EstadÃ­stica
- InvestigaciÃ³n
- Ciencia de datos

---

## âš¡ Lectura de todos los Parquet con Spark

Independientemente del lenguaje que escribiÃ³ el archivo:

```python
df = spark.read.parquet("path/to/parquet")



## ğŸŒ Â¿En quÃ© otros lenguajes puedes manipular Parquet?  
*(y que Spark puede leer sin problema)*

### â­ Lenguajes mÃ¡s importantes

| Lenguaje | LibrerÃ­a | Comentario |
|--------|--------|-----------|
| **Scala** | Spark / Parquet nativo | Lenguaje nativo de Spark |
| **Python** | pyarrow / fastparquet | El mÃ¡s usado |
| **Java** | Spark / parquet-avro | Enterprise |
| **R** | arrow | EstadÃ­stica |
| **SQL** | Spark SQL / Hive | Lectura directa |
| **C++** | Apache Arrow | Alto rendimiento |
| **Rust** | arrow-rs | Data infra moderna |
| **Go** | parquet-go | Servicios backend |
| **Julia** | Parquet.jl | Ciencia y research |

---

### ğŸ§  Lo importante (para Spark)

âœ” Spark **no pregunta**:
- en quÃ© lenguaje se creÃ³  
- en quÃ© sistema  
- en quÃ© librerÃ­a  

âœ” Spark **solo necesita**:
- Que el archivo sea **Parquet vÃ¡lido**
- Metadatos correctos
- Esquema consistente

---

### ğŸ¯ Mensaje clave para tu contenido (muy CaroData)

> â€œNo es Python vs Java vs R.  
> Es **Parquet + Spark**.â€

---

Si quieres, el siguiente paso puede ser:
- ğŸ¥ guion para un **Reel explicando esto**
- ğŸ“Š ejemplo leyendo **el mismo Parquet desde los 3**
- ğŸ§ª demo comparando **CSV vs Parquet**
- ğŸ§± versiÃ³n **Bronze â†’ Silver â†’ Gold**

Dime y lo armamos ğŸ”¥
